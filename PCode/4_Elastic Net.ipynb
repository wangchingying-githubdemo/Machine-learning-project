{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. ElasticNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import packages**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Set directories**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\munch\\Documents\\Cass MSc\\Term 3\\Machine Learning\\Coursework\\PCode\n"
     ]
    }
   ],
   "source": [
    "print(os.getcwd())\n",
    "dirRawData = \"../RawData/\"\n",
    "dirPData = \"../PData/\"\n",
    "dirPOutput = \"../POutput/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_name = dirPData + '02_df.pickle'\n",
    "with open(f_name, \"rb\") as f:\n",
    "    dict_ = pickle.load(f)\n",
    "    \n",
    "df_all_onehot = dict_['df_all_onehot']\n",
    "\n",
    "del f_name, dict_\n",
    "\n",
    "\n",
    "f_name = dirPData + '02_vars.pickle'\n",
    "with open(f_name, \"rb\") as f:\n",
    "    dict_ = pickle.load(f)\n",
    "    \n",
    "vars_ind_num = dict_['vars_ind_num']\n",
    "var_dep = dict_['var_dep']\n",
    "vars_ind_categorical = dict_['vars_ind_categorical']\n",
    "vars_ind_onehot = dict_['vars_ind_onehot']\n",
    "\n",
    "del f_name, dict_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Split data into training, validation and test folds**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_train  = np.where(df_all_onehot['fold'].isin(np.arange(0,8)))[0] #[0,1,2,3,4,5,6,7]\n",
    "idx_val    = np.where(df_all_onehot['fold'].isin([8,9]))[0] #[8,9]\n",
    "idx_design = np.where(df_all_onehot['fold'].isin(np.arange(0,10)))[0] #[0,1,2,3,4,5,6,7,8,9]\n",
    "idx_test = np.where(df_all_onehot['fold'].isin([10]))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vars_ind = vars_ind_num + vars_ind_onehot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare x and y data\n",
    "x = df_all_onehot[vars_ind].values\n",
    "y = df_all_onehot[var_dep].values\n",
    "\n",
    "y_train = y[idx_train]\n",
    "y_val = y[idx_val]\n",
    "y_design = y[idx_design]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Standardize the data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "standardScaler_ = StandardScaler()\n",
    "standardScaler_.fit(x[idx_train])\n",
    "\n",
    "X_train = standardScaler_.transform(x[idx_train])\n",
    "X_val   = standardScaler_.transform(x[idx_val])\n",
    "X_test = standardScaler_.transform(x[idx_test])\n",
    "X_design = standardScaler_.transform(x[idx_design])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Elastic Net using sklearn SGDClassifier**\n",
    "\n",
    "We use SGDClassifier as it allows us to change l1_ratio and alpha. \n",
    "l1_ratio = 0 corresponds to L2 penalty, and l1_ratio = 1 corresponds to L1 penalty. \n",
    "\n",
    "We begin with the default l1_ratio of 0.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
       "              early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
       "              l1_ratio=0.15, learning_rate='optimal', loss='log', max_iter=1000,\n",
       "              n_iter_no_change=5, n_jobs=None, penalty='elasticnet',\n",
       "              power_t=0.5, random_state=None, shuffle=True, tol=0.001,\n",
       "              validation_fraction=0.1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "EN = SGDClassifier(loss='log',penalty='elasticnet') #use elastic net with log-loss function\n",
    "EN.fit(X_train,np.ravel(y_train)) #fit model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction (probabilities)\n",
    "EN__pred_train_prob = EN.predict_proba(X_train)\n",
    "EN__pred_val_prob   = EN.predict_proba(X_val)\n",
    "EN__pred_test_prob = EN.predict_proba(X_test)\n",
    "\n",
    "#prediction (0 or 1)\n",
    "EN__pred_train = EN.predict(X_train)\n",
    "EN__pred_val   = EN.predict(X_val)\n",
    "EN__pred_test = EN.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score is 0.8999895930898116\n",
      "val score is 0.8865278368040799\n"
     ]
    }
   ],
   "source": [
    "#print accuracy of the training and validation\n",
    "train_score = EN.score(X_train,y_train)\n",
    "val_score = EN.score(X_val, y_val)\n",
    "print(\"train score is {}\".format(train_score))\n",
    "print(\"val score is {}\".format(val_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train auc: 0.6409818703121701\n",
      "val auc: 0.5969511475796622\n"
     ]
    }
   ],
   "source": [
    "#print roc_auc_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "auc_train = roc_auc_score(y_train,EN__pred_train)\n",
    "auc_val = roc_auc_score(y_val,EN__pred_val)\n",
    "print(\"train auc: {}\".format(auc_train))\n",
    "print(\"val auc: {}\".format(auc_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average score using 10 fold cross validation on design data: 0.9051999594523268\n",
      "average roc_auc score using 10 fold cross validation on design data: 0.7905287291911214\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "result_roc_auc = cross_val_score(EN, X_design, np.ravel(y_design), cv=10, scoring='roc_auc')\n",
    "result_accuracy = cross_val_score(EN, X_design, np.ravel(y_design), cv=10, scoring='accuracy')\n",
    "print(\"average score using 10 fold cross validation on design data: {}\".format(result_accuracy.mean()))\n",
    "print(\"average roc_auc score using 10 fold cross validation on design data: {}\".format(result_roc_auc.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Grid Search for Elastic Net**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "start_time = time.time()\n",
    "alpha = [0.001,0.01,0.1]\n",
    "l1_ratio = [0.15,0.25,0.35]\n",
    "param_grid = dict(alpha = alpha,l1_ratio = l1_ratio)\n",
    "grid = GridSearchCV(estimator=EN, param_grid=param_grid, cv = 10, n_jobs=-1, scoring='roc_auc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.836468 using {'alpha': 0.01, 'l1_ratio': 0.25}\n",
      "Execution time: 214.9397165775299 ms\n"
     ]
    }
   ],
   "source": [
    "grid_result = grid.fit(X_design,np.ravel(y_design))\n",
    "# Summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "print(\"Execution time: \" + str((time.time() - start_time)) + ' ms')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately the best accuracy score was not higher than the optimized logistic regression (l1) which was 0.85, thus we do not expect its kaggle score to be better. Its kaggle score was only 0.85632"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use optimized  EN to predict test data\n",
    "ENopt_= grid.predict(X_test)\n",
    "ENopt_prob = grid.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Save prediction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "f_name = dirPOutput + 'optimizeelasticnet.csv'\n",
    "\n",
    "df_test = pd.read_csv(dirRawData + 'test.csv')\n",
    "\n",
    "with open(f_name, 'w',newline='') as csvfile:\n",
    "    writer=csv.writer(csvfile,delimiter=',')\n",
    "    writer.writerow([\"id\", \"target\"])\n",
    "    writer.writerows(zip(df_test[df_test.columns[0]], ENopt_prob[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENopt_prob_design = grid.predict_proba(X_design)\n",
    "dict_ = {'ENopt_prob': ENopt_prob_design,\n",
    "        'ENopt_prob_test':ENopt_prob}\n",
    "\n",
    "f_name = dirPData + 'EN.pickle'\n",
    "with open(f_name, \"wb\") as f:\n",
    "    pickle.dump(dict_, f)\n",
    "del f_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
