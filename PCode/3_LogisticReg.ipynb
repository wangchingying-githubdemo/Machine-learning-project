{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. LogisticReg(sklearn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the problem we are dealing with is a classification problem where the dependent variable is binary, logistic regression is used over a linear regression\n",
    "\n",
    "Resources:\n",
    "- https://www.datacamp.com/community/tutorials/understanding-logistic-regression-python\n",
    "- https://towardsdatascience.com/building-a-logistic-regression-in-python-301d27367c24\n",
    "- https://www.datacamp.com/community/tutorials/parameter-optimization-machine-learning-models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import packages**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Set directories**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\munch\\Documents\\Cass MSc\\Term 3\\Machine Learning\\Coursework\\PCode\n"
     ]
    }
   ],
   "source": [
    "print(os.getcwd())\n",
    "dirRawData = \"../RawData/\"\n",
    "dirPData = \"../PData/\"\n",
    "dirPOutput = \"../POutput/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_name = dirPData + '02_df.pickle'\n",
    "with open(f_name, \"rb\") as f:\n",
    "    dict_ = pickle.load(f)\n",
    "    \n",
    "df_all_onehot = dict_['df_all_onehot']\n",
    "\n",
    "del f_name, dict_\n",
    "\n",
    "f_name = dirPData + '02_vars.pickle'\n",
    "with open(f_name, \"rb\") as f:\n",
    "    dict_ = pickle.load(f)\n",
    "    \n",
    "vars_ind_num = dict_['vars_ind_num']\n",
    "var_dep = dict_['var_dep']\n",
    "vars_ind_categorical = dict_['vars_ind_categorical']\n",
    "vars_ind_onehot = dict_['vars_ind_onehot']\n",
    "\n",
    "del f_name, dict_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Split data into training, validation and test folds**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_train  = np.where(df_all_onehot['fold'].isin(np.arange(0,8)))[0] #[0,1,2,3,4,5,6,7]\n",
    "idx_val    = np.where(df_all_onehot['fold'].isin([8,9]))[0] #[8,9]\n",
    "idx_design = np.where(df_all_onehot['fold'].isin(np.arange(0,10)))[0] #[0,1,2,3,4,5,6,7,8,9]\n",
    "idx_test = np.where(df_all_onehot['fold'].isin([10]))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vars_ind = vars_ind_num + vars_ind_onehot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Prepare X and Y datasets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare x and y data\n",
    "x = df_all_onehot[vars_ind].values\n",
    "y = df_all_onehot[var_dep].values\n",
    "\n",
    "y_train = y[idx_train]\n",
    "y_val = y[idx_val]\n",
    "y_design = y[idx_design]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Standardize the data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "standardScaler_ = StandardScaler()\n",
    "standardScaler_.fit(x[idx_train])\n",
    "\n",
    "X_train = standardScaler_.transform(x[idx_train])\n",
    "X_val   = standardScaler_.transform(x[idx_val])\n",
    "X_test = standardScaler_.transform(x[idx_test])\n",
    "X_design = standardScaler_.transform(x[idx_design])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**L2 Logistic Regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr2_= LogisticRegression(penalty='l2',solver='liblinear')\n",
    "lr2_.fit(X=X_train, y = np.ravel(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction (probabilities)\n",
    "lr2__pred_train_prob = lr2_.predict_proba(X_train)\n",
    "lr2__pred_val_prob   = lr2_.predict_proba(X_val)\n",
    "lr2__pred_test_prob = lr2_.predict_proba(X_test)\n",
    "\n",
    "#prediction (0 or 1 output)\n",
    "lr2__pred_train = lr2_.predict(X_train)\n",
    "lr2__pred_val   = lr2_.predict(X_val)\n",
    "lr2__pred_test = lr2_.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score is 0.9287126652096992\n",
      "val score is 0.9192520186995325\n"
     ]
    }
   ],
   "source": [
    "#print accuracy of the training and validation\n",
    "train_score = lr2_.score(X_train,y_train)\n",
    "val_score = lr2_.score(X_val, y_val)\n",
    "print(\"train score is {}\".format(train_score))\n",
    "print(\"val score is {}\".format(val_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save output for submission\n",
    "import csv\n",
    "f_name = dirPOutput + 'l2logreg.csv'\n",
    "\n",
    "df_test = pd.read_csv(dirRawData + 'test.csv')\n",
    "\n",
    "with open(f_name, 'w',newline='') as csvfile:\n",
    "    writer=csv.writer(csvfile,delimiter=',')\n",
    "    writer.writerow([\"id\", \"target\"])\n",
    "    writer.writerows(zip(df_test[df_test.columns[0]], lr2__pred_test_prob[:,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This baseline logistic regression with l2 penalty yielded a result of 0.85111 on kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Train Accuracy: 0.92726')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#confusion matrix\n",
    "from sklearn import metrics\n",
    "import seaborn as sns\n",
    "\n",
    "cm_val = metrics.confusion_matrix(y_val,lr2__pred_val)\n",
    "cm_train = metrics.confusion_matrix(y_train,lr2__pred_train)\n",
    "\n",
    "plt.figure(figsize = (12,10))\n",
    "\n",
    "plt.subplot(121)\n",
    "sns.heatmap(cm_val, annot= True, fmt = \"d\", linewidths=.5, square = True, cbar = False);\n",
    "plt.ylabel('actual')\n",
    "plt.xlabel('predicted')\n",
    "all_sample_title = 'Validation Accuracy: {0:.5f}'.format(val_score)\n",
    "plt.title(all_sample_title, size = 15)\n",
    "\n",
    "plt.subplot(122)\n",
    "sns.heatmap(cm_train, annot= True, fmt = \"d\", linewidths=.5, square = True, cbar = False);\n",
    "plt.ylabel('actual')\n",
    "plt.xlabel('predicted')\n",
    "all_sample_title = 'Train Accuracy: {0:.5f}'.format(train_score)\n",
    "plt.title(all_sample_title, size = 15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The confusion matrices above shows how accurate the predictions are, the elements in the diagonal are events in which the predicted value = actual value. For example, element(1,1) in the matrix shows the instances that the predicted value of 0 equaled to the actual value of 0; in other words, out of 2139 actual 0s, the model predicted 2096 correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average score using 10 fold cross validation on design data: 0.9179084137322124\n",
      "average roc_auc score using 10 fold cross validation on design data: 0.8301530696775012\n"
     ]
    }
   ],
   "source": [
    "#kfold cross validation for l2 Regression\n",
    "from sklearn.model_selection import KFold\n",
    "kf = KFold(n_splits=10, shuffle=False)\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "result_roc_auc = cross_val_score(lr2_, X_design, np.ravel(y_design), cv=kf, scoring='roc_auc')\n",
    "result_accuracy = cross_val_score(lr2_, X_design, np.ravel(y_design), cv=kf, scoring='accuracy')\n",
    "print(\"average score using 10 fold cross validation on design data: {}\".format(result_accuracy.mean()))\n",
    "print(\"average roc_auc score using 10 fold cross validation on design data: {}\".format(result_roc_auc.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train auc: 0.6645192647949824\n",
      "val auc: 0.6464906301748131\n"
     ]
    }
   ],
   "source": [
    "#print roc_auc_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "auc_train = roc_auc_score(y_train,lr2__pred_train)\n",
    "auc_val = roc_auc_score(y_val,lr2__pred_val)\n",
    "print(\"train auc: {}\".format(auc_train))\n",
    "print(\"val auc: {}\".format(auc_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fit using design data\n",
    "lr2_.fit(X=X_design, y = np.ravel(y_design))\n",
    "lr2__pred_test_prob = lr2_.predict_proba(X_test)\n",
    "lr2__pred_test = lr2_.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**L1 Logistic Regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l1',\n",
       "                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Using lasso regression -> penalty = l1\n",
    "lr1_= LogisticRegression(penalty = 'l1', solver ='liblinear')\n",
    "lr1_.fit(X=X_train, y = np.ravel(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction (probabilities)\n",
    "lr1__pred_train_prob = lr1_.predict_proba(X_train)\n",
    "lr1__pred_val_prob   = lr1_.predict_proba(X_val)\n",
    "lr1__pred_test_prob = lr1_.predict_proba(X_test)\n",
    "\n",
    "#prediction (0 or 1)\n",
    "lr1__pred_train = lr1_.predict(X_train)\n",
    "lr1__pred_val   = lr1_.predict(X_val)\n",
    "lr1__pred_test = lr1_.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score is 0.9272556977833282\n",
      "val score is 0.9196770080747981\n"
     ]
    }
   ],
   "source": [
    "#print accuracy of the training and validation\n",
    "train_score = lr1_.score(X_train,y_train)\n",
    "val_score = lr1_.score(X_val, y_val)\n",
    "print(\"train score is {}\".format(train_score))\n",
    "print(\"val score is {}\".format(val_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train auc: 0.6559755752452135\n",
      "val auc: 0.6467243842655097\n"
     ]
    }
   ],
   "source": [
    "#print roc_auc_score\n",
    "auc_train = roc_auc_score(y_train,lr1__pred_train)\n",
    "auc_val = roc_auc_score(y_val,lr1__pred_val)\n",
    "print(\"train auc: {}\".format(auc_train))\n",
    "print(\"val auc: {}\".format(auc_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average score using 10 fold cross validation on design data: 0.9185775894585964\n",
      "average roc_auc score using 10 fold cross validation on design data: 0.834327713670884\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "result_roc_auc = cross_val_score(lr1_, X_design, np.ravel(y_design), cv=kf, scoring='roc_auc')\n",
    "result_accuracy = cross_val_score(lr1_, X_design, np.ravel(y_design), cv=kf, scoring='accuracy')\n",
    "print(\"average score using 10 fold cross validation on design data: {}\".format(result_accuracy.mean()))\n",
    "print(\"average roc_auc score using 10 fold cross validation on design data: {}\".format(result_roc_auc.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fit using design data\n",
    "lr1_.fit(X=X_design, y = np.ravel(y_design))\n",
    "lr1__pred_test_prob = lr1_.predict_proba(X_test)\n",
    "lr1__pred_test = lr1_.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that the l1 regression had higher kfold cross validation scores than l2 regression. Thus we would expect l1 to give a better score on Kaggle. Next we employ grid search to optimize the parameters before submitting again on Kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Optimize Logistic Regression through grid search**\n",
    "\n",
    "We use grid search to optimize the parameter lambda,the parameter \"C\" = 1/lambda in sklearn's logistic regression function, and compare penalty = \"l1\" or \"l2\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "C=[0.05,0.1,1.0,1.5,2.0]\n",
    "penalty = [\"l1\",\"l2\"]\n",
    "param_grid = dict(penalty = penalty,C=C)\n",
    "lr_= LogisticRegression(solver ='liblinear')\n",
    "grid = GridSearchCV(estimator=lr_, param_grid=param_grid, cv = 10, n_jobs=-1, scoring = 'roc_auc')\n",
    "#cv = number of folds for validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.853389 using {'C': 0.05, 'penalty': 'l1'}\n"
     ]
    }
   ],
   "source": [
    "grid_result = grid.fit(X_design, np.ravel(y_design))\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_)) # Summarize results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The auc score (approx 0.85) is higher than the 10 fold cross validation auc scores (approx 0.83) for both the l1 and l2 regressions (trained on design data). Thus we expect this to yield a higher kaggle score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use optimized logistic regression to predict test data\n",
    "lropt_= grid.predict(X_test)\n",
    "lropt_prob = grid.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Save prediction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "f_name = dirPOutput + 'optimizelogisticreg.csv'\n",
    "\n",
    "df_test = pd.read_csv(dirRawData + 'test.csv')\n",
    "\n",
    "with open(f_name, 'w',newline='') as csvfile:\n",
    "    writer=csv.writer(csvfile,delimiter=',')\n",
    "    writer.writerow([\"id\", \"target\"])\n",
    "    writer.writerows(zip(df_test[df_test.columns[0]], lropt_prob[:,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the best parameters for the logistic regression, we managed to improve the kaggle score to 0.86802"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save data\n",
    "lropt_prob_design = grid.predict_proba(X_design)\n",
    "dict_ = {'lropt_prob': lropt_prob_design,\n",
    "        'lropt_prob_test':lropt_prob}\n",
    "\n",
    "f_name = dirPData + 'logreg.pickle'\n",
    "with open(f_name, \"wb\") as f:\n",
    "    pickle.dump(dict_, f)\n",
    "del f_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
